### ğŸ”§ Scenario

We simulate a streaming human-control task with **1000 timesteps**:

- First half: slower, smoother human control  
- Second half: higher tempo, more variability (increased workload)  

There is **no training phase**, **no labels**, and **no supervision**.

### ğŸ“Œ Question

> Can HTM-State autonomously detect this behavioral mode change  
> *directly from streaming behavior*?

âœ” Yes â€” typically within **1â€“2 seconds** at 10 Hz.  
A representative run is shown below.

This matters because:
* conventional anomaly detectors require retraining  
* supervised workload models need labeled sessions  
* HTM-State learns adaptively and online  

---

### ğŸ’» Offline Evaluation

```bash
python -m scripts.offline_demo_detection_lag \
    --csv demos/workload_demo/synthetic_workload.csv \
    --backend htm \
    --rate-hz 10
```

Example output:

```text
Processed 1000 steps...
Using ground-truth toggle_step = 501
Detection lag: 5 steps
Detection lag: 0.500 s at 10 Hz
```

### ğŸ” Interpretation

HTM-State detects the behavioral state shift  
**within ~0.5â€“1.5 seconds** of onset.

This represents **nearâ€“real-time behavioral awareness** without supervision.

---

### ğŸ¥ Live Visualization

```bash
python -m scripts.live_demo_state --backend htm --rate-hz 10
```

The live visualization shows two scrolling plots:

1. **Control signals**  
2. **HTM State + detected spikes (orange dots)**  

### âœ… What good detection looks like

âœ” transition spike occurs shortly after the real change  
âœ” few false alarms outside transition period  

### Failure modes

âŒ spikes long after the boundary â†’ slow reaction  
âŒ spikes before the boundary â†’ overly sensitive detector 

### ğŸ” Interpretation
* HTM-State **detected behavioral state shifts** with strong speed & precision.

---

### ğŸ“Œ Takeaway  

Demo 1 validates HTM-State for:

- âœ” online learning (no split training data)  
- âœ” unsupervised change detection  
- âœ” fast response  
- âœ” precision  

