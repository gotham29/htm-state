# HTM-State  
**Continuous online anomaly learning and operator/system state awareness across domains.**

HTM-State is a real-time adaptive sensing system inspired by the neocortex.  
It continuously learns patterns in streaming data, estimates underlying state,  
detects transitions, and measures detection latency â€” all **without retraining or supervision**.

It is designed to operate across domains:

- Human workload / pilot cognition  
- Cyber intrusion / behavioral drift  
- Surgical performance change  
- Manufacturing process instability  
- UAV operator skill and safety  
- Edge intelligence / autonomous agents  

HTM-State provides a **unified operational pipeline** that can be deployed wherever  
behavioral pattern drift, safety monitoring, or cognitive state awareness is needed.

---

## ğŸ“š Contents

- [ğŸŒ Why HTM-State exists](#-why-htm-state-exists)
- [ğŸ” Core Architecture](#-core-architecture)
- [âœ¨ What the repo includes](#-what-the-repo-includes)
- [âš¡ Quickstart](#-quickstart)
- [ğŸ”¬ Demo 1 â€” Real-Time Workload Transition Detection](#-demo-1--real-time-workload-transition-detection)
- [ğŸ” Demo 2 â€” Cyber Behavior Drift Detection (UNSW-NB15)](#-demo-2--cyber-behavior-drift-detection-unsw-nb15)
- [ğŸ¥ Demo 3 â€” Healthcare Operator Workload (coming soon)](#-demo-3--healthcare-operator-workload-coming-soon)
- [ğŸ›  Architecture Components](#-architecture-components)
- [ğŸ“¦ Development Roadmap](#-development-roadmap)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“§ Contact / Project Lead](#-contact--project-lead)

---

## ğŸŒ Why HTM-State exists

Conventional ML assumes:

- stationarity  
- batch retraining  
- labeled supervision  
- slow detection response  

**But real systems drift continuously.**

Human operators change mode.  
Networks degrade before they fail.  
Intrusions evolve stealthily.  
Machines deteriorate gradually.

HTM-State solves this by:
  
âœ” **Online learning in nonstationary environments**  
âœ” **No supervision or labels required**  
âœ” **No retraining or fine-tuning needed**  
âœ” **Sub-second response and change detection**  
âœ” **Works in domains where human + machine co-adapt**

---

## ğŸ” Core Architecture

```text
Input features  â”€â”€â–º HTM Encoder + SP + TM  â”€â–º Anomaly
                                            â”‚
                                            â–¼
                                     State Estimator (EMA)
                                            â”‚
                                            â–¼
                              Growth-based Spike Detector
                                            â”‚
                                            â–¼
                        Transition detection + latency metric
```

This structure is **domain-agnostic** â€” swapping input features yields new applications without rewriting logic.

---

## âœ¨ What the repo includes

- A pluggable HTM engine backend  
- Online state estimator (EMA/Fusion) 
- Growth-based spike detector  
- Detection lag metric  
- Live streaming visualizer  
- Offline evaluation tool  
- Synthetic workload dataset  
- A reusable demo spec template (`docs/demo_template.md`) for new domains  
- A path to multiple domain demos  

---

# âš¡ Quickstart

```bash
# 1) Create & activate env (example)
conda create -n htm_env python=3.9 -y
conda activate htm_env

# 2) Install dependencies (from repo root)
pip install -r requirements.txt

# 3) Run Demo 1 (workload)
python -m scripts.offline_demo_detection_lag \
    --csv demos/workload_demo/synthetic_workload.csv \
    --backend htm \
    --rate-hz 10

python -m scripts.live_demo_state --backend htm --rate-hz 10

# 4) Run Demo 2 (cyber drift)
python -m scripts.offline_demo_cyber \
    --csv demos/cyber_demo/unsw_cyber_stream.csv \
    --rate-hz 10

python -m scripts.live_demo_cyber \
    --csv demos/cyber_demo/unsw_cyber_stream.csv \
    --rate-hz 10
```

Once those are working, you can tweak spike detector and HTM parameters via the CLI flags in each script to explore different sensitivities and response speeds.

---

# ğŸ”¬ Demo 1 â€” Real-Time Workload Transition Detection

This first demo illustrates HTM-State applied to **pilot-style psychomotor workload dynamics**  
(e.g., UAV control, piloting, teleoperation, manual tracking tasks).

### âœˆï¸ Scenario

We simulate 1000 steps of control activity:

- First half: slower, smoother human control  
- Second half: higher tempo, more variability (increased workload)  

There is **no training data** and **no supervision**.

### ğŸ“Œ Question

> Can the system autonomously detect this internal mode change just from streaming behavior?

âœ” Yes â€” with detection lag typically around **1â€“2 seconds** at 10 Hz  
depending on spike sensitivity parameters. A representative run is shown below.

This is significant because:
* conventional anomaly detectors require retraining
* supervised workload models need labeled sessions
* HTM-State learns on the fly and adapts autonomously

---

## ğŸ’» Running Demo 1 (Offline Evaluation)

```bash
python -m scripts.offline_demo_detection_lag \
    --csv demos/workload_demo/synthetic_workload.csv \
    --backend htm \
    --rate-hz 10
```

Example output:

```text
Processed 1000 steps...
Using ground-truth toggle_step = 501
Detection lag: 5 steps
Detection lag: 0.500 s at 10 Hz
```

### â¤ Interpretation (Demo 1)

HTM-State detects the workload shift  
**within half a second**  
of its onset.

That represents near-real-time awareness without supervision.

---

## ğŸ¥ Live Visualization

```bash
python -m scripts.live_demo_state --backend htm --rate-hz 10
```

This shows two scrolling plots:

1. **Control signals**  
2. **HTM State + detected spikes**  

Spikes at transition points reflect **detected workload shifts**.

> Additional small spikes typically represent exploratory deviations or behavioral anomalies â€” useful for safety monitoring and drift awareness.

---
## ğŸ¥ Demo 1 â€” Live Transition Animation

![HTM-State Demo 1 Live Transition](docs/gifs/demo1.gif)

*HTM-State continuously learns operator behavior in real time.*

### ğŸ” Interpretation

âœ” **Blue curve** â€” estimated workload state  
âœ” **Orange spikes** â€” detected regime shift  

### âœ… What good detection looks like
âœ” transition spike occurs shortly after the real change  
âœ” few false alarms outside transition period  

### ğŸ“Œ Takeaway  
Detection occurs **within ~1â€“2 seconds**, without offline training or calibration.

---

## ğŸ§  Why Demo 1 matters

Demo 1 validates:

- âœ” online learning  
- âœ” unsupervised change detection  
- âœ” fast response  
- âœ” streaming embodiment  
- âœ” generality of approach  

This validates HTM-State as a domain-agnostic adaptive inference engine.

# ğŸš€ What Demo 1 proves

âœ” HTM-State reacts in sub-second time  
âœ” It requires **no labeled training data**  
âœ” It adapts online like a human observer  
âœ” It generalizes across domains â€” workload today, cyber and healthcare tomorrow   

---

## ğŸ” Demo 2 â€” Cyber Behavior Drift Detection (UNSW-NB15)

Cyber systems drift continuously â€” sometimes without explicit attack signatures.  
This demo applies HTM-State to **streaming packet-flow behavior** derived from UNSW-NB15.

### ğŸ” Scenario

We generate a streaming sequence with three true drift boundaries:

* stable period  
* small statistical change  
* larger behavioral shift  

Ground-truth boundary times are marked visually with **vertical dashed red lines**.

### ğŸ“Œ Question

> Can HTM-State detect emerging cyber behavior shifts  
> *without* retraining, classifiers, or labels?

âœ” Yes â€” it learns online and responds autonomously.

### ğŸ“Š Offline Evaluation Output

Example:

```bash
python -m scripts.offline_demo_cyber \
    --csv demos/cyber_demo/unsw_cyber_stream.csv \
    --rate-hz 10
```

Example output:

```text
Found 3 drift boundaries at steps: [500, 1000, 1500]

=== Drift Detection Results ===
Drift 0: boundary at step 500 (t=50.000s) â†’ detected at step 535 (t=53.500s), lag = 35 steps (3.500 s)
Drift 1: boundary at step 1000 (t=100.000s) â†’ detected at step 1073 (t=107.300s), lag = 73 steps (7.300 s)
Drift 2: boundary at step 1500 (t=150.000s) â†’ detected at step 1534 (t=153.400s), lag = 34 steps (3.400 s)

Average detection lag over 3 drifts: **4.7 s**
```

This represents **model-free cyber drift detection** using the same core pipeline that detected human workload changes.

### ğŸ“ˆ Live Visualization (Demo 2)

```bash
python -m scripts.live_demo_cyber \
    --csv demos/cyber_demo/unsw_cyber_stream.csv \
    --rate-hz 10
```

Live visualization shows:

- selected network features (e.g., rate, sload, dload)
- HTM cyber-state (anomaly-driven state estimate)
- true drift boundaries (red dashed lines)
- detected drift spikes (orange dots)
- magenta lag bars quantifying detection latency

This demonstrates domain generality â€”
HTM-State adapts online whether its input is human control or network behavior.

---

---

## ğŸ¥ Demo 2 â€” Cyber Drift Live Animations

Three short sequences illustrate how HTM-State responds to each true drift boundary:

<p align="center">
  <img src="docs/gifs/demo2_50s.gif" width="950"/>
</p>

<p align="center">
  <img src="docs/gifs/demo2_100s.gif" width="950"/>
</p>

<p align="center">
  <img src="docs/gifs/demo2_150s.gif" width="950"/>
</p>

### ğŸ” Interpretation  

âœ” **Orange dots** â€” detected drift spikes  
âœ” **Red dashed line** â€” true drift boundary  
âœ” **Magenta bar** â€” lag from boundary â†’ detection  

### âœ… What good detection looks like
âœ” spikes appear very close to the red line  
âœ” magenta bars are short  

### âš ï¸ Failure modes to watch for
âŒ spikes appear far after the red line â†’ slow reaction  
âŒ repeated spikes with no boundary â†’ false positives  

### ğŸ“Œ Takeaway  
ğŸ‘‰ **Same pipeline as Demo 1 â€” different domain â€” no retraining required.**

---

# ğŸ¥ Demo 3 â€” Healthcare Operator Workload *(planned)*

This planned demo will apply HTM-State to **clinical operator behavior**  
â€” for example ICU nurses, surgeons, or interventionalists â€” to detect shifts in  
moment-to-moment workload and performance using the **same HTM-State pipeline**  
as the workload and cyber demos.

---

### ğŸ©º Scenario (planned)

- Continuous motion / interaction features  
  (e.g., tool motion, cursor motion, gaze, device interaction)  
- Periods of routine activity vs. high-acuity events  
  (e.g., crisis, complex maneuver, high cognitive load)  
- No labeled workload scores at run time â€” only behavior streams  

---

### ğŸ“Œ Question

> Can HTM-State surface **emerging overload or performance change**  
> fast enough to support safety and staffing decisions?

The intent mirrors Demos 1 & 2:

- learn **online** from operator behavior  
- detect **transitions** in workload / performance state  
- report **detection latency** in seconds  

---

### ğŸ“Š Planned Offline Evaluation

The healthcare demo will reuse the **same pipeline** as workload and cyber:

1. Encode behavioral / motion signals into HTM input features  
2. Run anomaly â†’ EMA state â†’ spike detector  
3. Compare spike times to known regime changes (e.g., annotated events)  
4. Report detection lags and false-alarm behavior  

Once the dataset and scripts are finalized, this section will include:

- offline evaluation CLI (e.g., `python -m scripts.offline_demo_healthcare`)  
- representative detection-lag output (similar to Demos 1 & 2)  

---

### ğŸ“ˆ Planned Live Visualization

The live demo will mirror the existing visuals:

- **Top panel** â€” selected motion / interaction features  
- **Bottom panel** â€” HTM state, spikes, and ground-truth change markers  
- **Magenta lag bars** â€” time from event â†’ detection  

Short GIFs (like Demos 1 & 2) will be added here once the demo is recorded  
and will follow the same interpretation structure (good detection vs. failure modes).

---

### ğŸ§  Why Demo 3 matters

Demo 3 will extend HTM-State into **high-stakes humanâ€“in-the-loop** settings:

- early visibility into operator overload / fatigue  
- continuous performance drift monitoring without labels  
- a single pipeline that spans **pilots â†’ cyber analysts â†’ clinicians**  

It is designed as a bridge toward real deployments in:

- patient safety and quality improvement  
- staffing and acuity-aware scheduling  
- AR/VR assistance and training feedback 
@@
---

---

# ğŸ›  Architecture Components

### âœ” HTM Backend

Encoders + Spatial Pooler + Temporal Memory using biologically-inspired learning.

### âœ” State Engine

Smooths anomaly into interpretable state estimates.

### âœ” Spike Detector

Detects transitions via growth differential logic.

### âœ” Detection Lag Metric

Measures adaptation time â€” critical in safety systems.

---

# ğŸ“¦ Development Roadmap

| Phase  | Target                       |
|-------|------------------------------|
| Demo 1 | pilot workload transition    |
| Demo 2 | cyber drift detection        |
| Demo 3 | healthcare workload          |
| Demo 4 | industrial predictive change |
| Demo 5 | UAV safety horizon estimation |

---

# ğŸ¤ Contributing

Future collaborators welcome â€”  
especially for new datasets in cyber, healthcare, robotics, or autonomy.

---

# ğŸ“Œ Want to collaborate?

If you are interested in safety monitoring, autonomy, performance assessment,  
pilot modeling, cybersecurity drift detection, or cognitive systems â€” get in touch.

# ğŸ“§ Contact / Project Lead

Sam Heiserman  
Creator â€” HTM-State  
sheiser1@binghamton.edu